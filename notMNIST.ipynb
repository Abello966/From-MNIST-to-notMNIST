{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GT 630M (CNMeM is disabled)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "from helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Normally construct the CNN, but keep and return the reference to the last convolutional layer\n",
    "def build_cnn_with_conv(input_var=None):\n",
    "    # Input layer\n",
    "    network = lasagne.layers.InputLayer(shape=(None, 1, 28, 28),\n",
    "                                        input_var=input_var)\n",
    "\n",
    "    # Convolutional layer with 32 kernels of size 5x5. Strided and padded\n",
    "    # convolutions are supported as well; see the docstring.\n",
    "    network = lasagne.layers.Conv2DLayer(\n",
    "            network, num_filters=32, filter_size=(5, 5),\n",
    "            nonlinearity=lasagne.nonlinearities.rectify,\n",
    "            W=lasagne.init.GlorotUniform())\n",
    "\n",
    "    # Max-pooling layer of factor 2 in both dimensions:\n",
    "    network = lasagne.layers.MaxPool2DLayer(network, pool_size=(2, 2))\n",
    "\n",
    "    # Another convolution with 32 5x5 kernels, and another 2x2 pooling:\n",
    "    network = lasagne.layers.Conv2DLayer(\n",
    "            network, num_filters=32, filter_size=(5, 5),\n",
    "            nonlinearity=lasagne.nonlinearities.rectify)\n",
    "    conv = lasagne.layers.MaxPool2DLayer(network, pool_size=(2, 2))\n",
    "\n",
    "    # A fully-connected layer of 256 units with 50% dropout on its inputs:\n",
    "    network = lasagne.layers.DenseLayer(\n",
    "            lasagne.layers.dropout(conv, p=.5),\n",
    "            num_units=256,\n",
    "            nonlinearity=lasagne.nonlinearities.rectify)\n",
    "\n",
    "    # And, finally, the 10-unit output layer with 50% dropout on its inputs:\n",
    "    network = lasagne.layers.DenseLayer(\n",
    "            lasagne.layers.dropout(network, p=.5),\n",
    "            num_units=10,\n",
    "            nonlinearity=lasagne.nonlinearities.softmax)\n",
    "\n",
    "    return network, conv #conv is the last conv layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Build and populate network\n",
    "input_var = T.tensor4('input')\n",
    "network, conv = build_cnn_with_conv(input_var)\n",
    "\n",
    "#This network had 95% test accuracy on MNIST\n",
    "with np.load('model.npz') as f:\n",
    "    param_values = [f['arr_%d' % i] for i in range(len(f.files))]\n",
    "lasagne.layers.set_all_param_values(network, param_values)\n",
    "\n",
    "#Compile function to generate features\n",
    "output_var = lasagne.layers.get_output(conv)\n",
    "feat_extract = theano.function([input_var], output_var)\n",
    "\n",
    "#Load dataset\n",
    "train_dataset, train_labels, test_dataset, test_labels = load_not_mnist_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data\n",
      "Loading test data\n"
     ]
    }
   ],
   "source": [
    "#Extract features, one by one so we dont explode memory\n",
    "train_feats = np.empty((200000, 512), dtype='float32')\n",
    "print(\"Loading training data\")\n",
    "for i in range(train_dataset.shape[0]):\n",
    "    feats = feat_extract(train_dataset[i].reshape((1, 1, 28, 28)))\n",
    "    train_feats[i] = np.array(feats.reshape((512)))\n",
    "    \n",
    "print(\"Loading test data\")\n",
    "test_feats = np.empty((test_dataset.shape[0], 512), dtype='float32')\n",
    "for i in range(test_dataset.shape[0]):\n",
    "    feats = feat_extract(test_dataset[i].reshape((1, 1, 28, 28)))\n",
    "    test_feats[i] = np.array(feats.reshape((512)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took  382.03640270233154  seconds\n",
      "Validation score:  0.853575\n",
      "Test score:  0.9053\n"
     ]
    }
   ],
   "source": [
    "#Trains logistic regression on extracted features\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log = LogisticRegression()\n",
    "start_time = time.time()\n",
    "log.fit(train_feats, train_labels)\n",
    "print(\"Training took \", time.time() - start_time, \" seconds\")\n",
    "print(\"Validation score: \", log.score(train_feats, train_labels))\n",
    "print(\"Test score: \", log.score(test_feats, test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned features:\n",
      "Validation score:  0.622372507308\n",
      "Test score:  0.690627017155\n",
      "\n",
      "Whole image:\n",
      "Validation score:  0.552986870496\n",
      "Test score:  0.641092281194\n"
     ]
    }
   ],
   "source": [
    "#Trains linear regression on both extracted features and whole image for comparison\n",
    "import time\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "print(\"Learned features:\")\n",
    "lin = LinearRegression()\n",
    "lin.fit(train_feats, train_labels)\n",
    "print(\"Validation score: \", lin.score(train_feats, train_labels))\n",
    "print(\"Test score: \", lin.score(test_feats, test_labels))\n",
    "\n",
    "\n",
    "#Train logistic regression with image as features for comparison\n",
    "print(\"\\nWhole image:\")\n",
    "train_dataraw = train_dataset.reshape((train_dataset.shape[0], 28 * 28))\n",
    "test_dataraw = test_dataset.reshape((test_dataset.shape[0], 28 * 28))\n",
    "lin_raw = LinearRegression()\n",
    "lin_raw.fit(train_dataraw, train_labels)\n",
    "print(\"Validation score: \", lin_raw.score(train_dataraw, train_labels))\n",
    "print(\"Test score: \", lin_raw.score(test_dataraw, test_labels))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
